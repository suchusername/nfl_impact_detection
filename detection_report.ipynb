{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.Processor import load_detection_ds, Processor\n",
    "from matplotlib import cm as mp_cm\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import image, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(\n",
    "    image,\n",
    "    bboxes,\n",
    "    colors=None,\n",
    "    color_by=\"class\",\n",
    "    show_desc=True,\n",
    "    show_label=True,\n",
    "    show_conf=True,\n",
    "    show_trackid=True,\n",
    "    naming_path=None,\n",
    "    colormap=\"gist_ncar\",\n",
    "    line_thickness=None,\n",
    "    style=None,\n",
    "    desc_scale=1,\n",
    "    desc_style=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes, confidence and labels on an image. Label names are taken from the file `naming_csv`\n",
    "    \n",
    "    Arguments:\n",
    "    image         : np.array of shape (?,?,3) with np.uint8 data type in RGB format, \n",
    "        otherwise it is assumed that normalized image is given.\n",
    "    bboxes        : list or numpy array with columns [x_min, y_min, width, height, label, score, track_id],\n",
    "        where (x_min, y_min) are coordinates of top left corner,\n",
    "              label - an integer encoding a class, if missing, it is 0 by default ('person'),\n",
    "              score - confidence of a prediction, a float in [0,1]\n",
    "              track_id - an integer encoding a track that this bbox belongs to\n",
    "        Last 3 columns are optional.\n",
    "    colors        : a list of color names for different classes of bboxes (Ex: ['red', 'blue']),\n",
    "        for color names refer to https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "    color_by      : \"class\" or \"track\", which category is supposed to have different colors (default: \"class\")\n",
    "    show_desc     : whether to draw description (class label, confidence and track id) or not\n",
    "    show_label    : whether to draw labels with classes or not\n",
    "    show_conf    : whether to show confidence score or not\n",
    "    show_trackid  : whether to show track id or not\n",
    "    naming_path   : path to file with labels\n",
    "    colormap      : str, name of matplotlib colormap to use (default: \"gist_ncar\")\n",
    "    line_thickness: int, thickness of a bounding box in pixels (default is determined by image size)\n",
    "    style         : str, None or \"dashed\" (default: None)\n",
    "    desc_scale    : float, size of description relative to automatic size (default: 1),\n",
    "    desc_style    : 0 or 1, two different styles of description (default: 0)\n",
    "                                        \n",
    "    Returns:\n",
    "    transformed numpy array of shape (?,?,3) with image data of type np.uint8\n",
    "    \"\"\"\n",
    "    # # 1. Input preparation\n",
    "\n",
    "    # Converting to np.uint8\n",
    "    if image.dtype != np.uint8:\n",
    "        warnings.warn(\n",
    "            \"Converting image to np.uint8 myself assuming [0,1] range, can break something, consider converting yourself\"\n",
    "        )\n",
    "        image = np.clip((image * 255).astype(np.uint8), 0, 255)\n",
    "    else:\n",
    "        image = image.copy()\n",
    "\n",
    "    # checking arguments\n",
    "    if style not in [None, \"dashed\"]:\n",
    "        raise ValueError(\n",
    "            f\"Unknown style `{style}`. It must be either None or `dashed`.\"\n",
    "        )\n",
    "    if color_by not in [\"class\", \"track\"]:\n",
    "        raise ValueError(\n",
    "            f\"Unknown color target `{color_by}`. It must be either `class` or `track`.\"\n",
    "        )\n",
    "    if color_by == \"track\" and bboxes.shape[1] < 7:\n",
    "        raise ValueError(\n",
    "            f\"Cannot set color target to `track`, because bboxes do not have track ids.\"\n",
    "        )\n",
    "    if bboxes.shape[1] < 7:\n",
    "        show_trackid = False\n",
    "        if bboxes.shape[1] < 6:\n",
    "            show_conf = False\n",
    "    if desc_style not in [0, 1]:\n",
    "        raise ValueError(\n",
    "            f\"Unknown description style `{desc_style}`. It must be either 0 or 1.\"\n",
    "        )\n",
    "\n",
    "    bboxes = bboxes[bboxes.sum(axis=1) > 0]\n",
    "\n",
    "    # clipping bboxes\n",
    "    image_h, image_w, _ = image.shape\n",
    "    bboxes[:, 2:4] += bboxes[:, 0:2]\n",
    "    bboxes[:, [0, 2]] = np.clip(bboxes[:, [0, 2]], 1, image_w - 1)\n",
    "    bboxes[:, [1, 3]] = np.clip(bboxes[:, [1, 3]], 1, image_h - 1)\n",
    "    bboxes[:, 2:4] -= bboxes[:, 0:2]\n",
    "\n",
    "    if bboxes.shape[1] >= 6:\n",
    "        asrt = np.argsort(bboxes[:, 5])\n",
    "        bboxes = bboxes[asrt]\n",
    "\n",
    "    # add class label (adding 0s), if it is missing\n",
    "    if bboxes.shape[1] == 4:\n",
    "        bboxes = np.concatenate(\n",
    "            [bboxes, np.zeros((bboxes.shape[0], 1), dtype=bboxes.dtype),], axis=-1,\n",
    "        )\n",
    "\n",
    "    # getting classes dict {label: name}, if naming.csv is not passed then it is {label: label}\n",
    "    if naming_path is not None:\n",
    "        classes = getClasses(naming_path)\n",
    "        # checking if bboxes have classes that are not in naming.csv. If there are, they are added as {label:label}\n",
    "        present_classes = np.unique(bboxes[:, 4]).astype(int)\n",
    "        warned = False\n",
    "        for c in present_classes:\n",
    "            if c not in classes.keys():\n",
    "                if not warned:\n",
    "                    warnings.warn(\n",
    "                        \"Bboxes have class labels which are not described in naming.csv.\"\n",
    "                    )\n",
    "                    warned = True\n",
    "                classes[c] = str(c)\n",
    "    else:\n",
    "        classes = {0: \"h\"}\n",
    "        # if len(bboxes) > 0:\n",
    "        #    classes = {int(c): str(int(c)) for c in np.unique(bboxes[:, 4])}\n",
    "\n",
    "    # setting colors, it is dict {label: color},\n",
    "    # where color is np.array of shape (3,) with R, G, B values in [0, 255] range\n",
    "    if color_by == \"class\":\n",
    "        color_by_col = 4\n",
    "    elif color_by == \"track\":\n",
    "        color_by_col = 6\n",
    "    present_categories = np.unique(bboxes[:, color_by_col]).astype(int)\n",
    "\n",
    "    if colors is None:\n",
    "        # automatically loading colors from colormap\n",
    "        colormap = mp_cm.get_cmap(colormap)\n",
    "\n",
    "        def label_to_color(c):\n",
    "            idx = 0.8 * int(format(c, \"016b\")[::-1], 2) / (2 ** 16) + 0.2\n",
    "            return np.array(colormap(idx)[:3]) * 255\n",
    "\n",
    "        colors_dict = {int(c): label_to_color(c) for c in present_categories}\n",
    "\n",
    "    else:\n",
    "        # colors are specified by user\n",
    "        if len(colors) < len(present_categories):\n",
    "            raise ValueError(\n",
    "                f\"Not enough colors are specified. Bboxes have {len(present_categories)} different categories.\"\n",
    "            )\n",
    "        colors = colors[: len(present_categories)]\n",
    "        colors_dict = {\n",
    "            int(c): (np.array(mp_colors.to_rgb(col)) * 255)\n",
    "            for c, col in zip(present_categories, colors)\n",
    "        }\n",
    "\n",
    "    # setting writing and drawing arguments\n",
    "    fontscale = (image_h / 1200.0) * desc_scale\n",
    "\n",
    "    if line_thickness is None:\n",
    "        line_thickness = max(1, round(0.8 * (image_h + image_w) / 600))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # # 2. Drawing bboxes\n",
    "\n",
    "    for bbox in bboxes:\n",
    "\n",
    "        # drawing a bounding box\n",
    "        c0 = (int(bbox[0]), int(bbox[1]))  # top left\n",
    "        c1 = (int(bbox[0]) + int(bbox[2]), int(bbox[1]) + int(bbox[3]))  # bottom right\n",
    "        bbox_color = colors_dict[int(bbox[color_by_col])]\n",
    "\n",
    "        if style == \"dashed\":\n",
    "            dashed_rectangle(image, c0, c1, bbox_color, thickness=line_thickness)\n",
    "        else:\n",
    "            cv2.rectangle(image, c0, c1, bbox_color, line_thickness)\n",
    "\n",
    "    # # 3. Drawing descriptions\n",
    "\n",
    "    if show_desc:\n",
    "\n",
    "        for bbox in bboxes:\n",
    "\n",
    "            c0 = (int(bbox[0]), int(bbox[1]))  # top left\n",
    "            c1 = (\n",
    "                int(bbox[0]) + int(bbox[2]),\n",
    "                int(bbox[1]) + int(bbox[3]),\n",
    "            )  # bottom right\n",
    "            bbox_label = int(bbox[4])\n",
    "            bbox_color = colors_dict[int(bbox[color_by_col])]\n",
    "\n",
    "            messages = []\n",
    "            messages_fontscale = []\n",
    "            if show_label:\n",
    "                messages.append(classes[bbox_label][0])\n",
    "                messages_fontscale.append(fontscale)\n",
    "            if show_conf:\n",
    "                bbox_conf = bbox[5]\n",
    "                messages.append(str(int(round(bbox_conf, 2) * 100)) + \"%\")\n",
    "                messages_fontscale.append(fontscale * 0.6)\n",
    "            if show_trackid:\n",
    "                bbox_trackid = bbox[6]\n",
    "                messages.append(\"#\" + str(int(bbox_trackid)))\n",
    "                messages_fontscale.append(fontscale * 0.6)\n",
    "\n",
    "            if len(messages) > 0:\n",
    "\n",
    "                messages_size = [\n",
    "                    cv2.getTextSize(msg, font, messages_fontscale[i], thickness=1)[0]\n",
    "                    for i, msg in enumerate(messages)\n",
    "                ]\n",
    "                max_message_length = max([w for w, h in messages_size])\n",
    "\n",
    "                # calculating positions for text\n",
    "                messages_coords = []\n",
    "                y_pos = c0[1]  # y-coord of top corner of bbox\n",
    "\n",
    "                if (c1[0] + max_message_length + 3 <= image_w) and (\n",
    "                    (bbox_label == 0) or (c0[0] - max_message_length - 5 < 0)\n",
    "                ):\n",
    "                    right_pos = True\n",
    "                else:\n",
    "                    right_pos = False\n",
    "\n",
    "                for size in messages_size:\n",
    "                    y_pos += size[1]\n",
    "                    if right_pos:\n",
    "                        # description is to the right of bbox\n",
    "                        text_c = (\n",
    "                            c1[0] + 5,  # x-coord of bottom left corner of text\n",
    "                            y_pos,  # y-coord\n",
    "                        )\n",
    "                    else:\n",
    "                        # description is to the left of bbox\n",
    "                        text_c = (\n",
    "                            c0[0]\n",
    "                            - 5\n",
    "                            - size[0],  # x-coord of bottom left corner of text\n",
    "                            y_pos,  # y-coord\n",
    "                        )\n",
    "                    y_pos += 5 * desc_scale\n",
    "                    messages_coords.append(text_c)\n",
    "\n",
    "                # adding some background\n",
    "                if desc_style == 0:\n",
    "\n",
    "                    bg_top = c0[1]\n",
    "                    bg_bottom = y_pos\n",
    "                    bg_left = c1[0] if right_pos else (c0[0] - max_message_length - 5)\n",
    "                    bg_right = bg_left + max_message_length + 6\n",
    "                    sub_image = np.array(\n",
    "                        image[bg_top:bg_bottom, bg_left:bg_right], dtype=np.uint8\n",
    "                    )\n",
    "                    bg_rect = np.concatenate(\n",
    "                        [\n",
    "                            np.ones(shape=(sub_image.shape[0], sub_image.shape[1], 1))\n",
    "                            * bbox_color[0],\n",
    "                            np.ones(shape=(sub_image.shape[0], sub_image.shape[1], 1))\n",
    "                            * bbox_color[1],\n",
    "                            np.ones(shape=(sub_image.shape[0], sub_image.shape[1], 1))\n",
    "                            * bbox_color[2],\n",
    "                        ],\n",
    "                        axis=-1,\n",
    "                    ).astype(np.uint8)\n",
    "                    bg_res = cv2.addWeighted(sub_image, 0.4, bg_rect, 0.6, 1.0)\n",
    "                    image[bg_top:bg_bottom, bg_left:bg_right] = bg_res\n",
    "\n",
    "                # putting text\n",
    "                if desc_style == 0:\n",
    "\n",
    "                    for i in range(len(messages)):\n",
    "                        cv2.putText(\n",
    "                            image,\n",
    "                            messages[i],\n",
    "                            messages_coords[i],\n",
    "                            font,\n",
    "                            messages_fontscale[i],\n",
    "                            (0, 0, 0),\n",
    "                            thickness=1,\n",
    "                            lineType=cv2.LINE_AA,\n",
    "                        )\n",
    "\n",
    "                elif desc_style == 1:\n",
    "\n",
    "                    for i in range(len(messages)):\n",
    "                        cv2.putText(\n",
    "                            image,\n",
    "                            messages[i],\n",
    "                            messages_coords[i],\n",
    "                            font,\n",
    "                            messages_fontscale[i],\n",
    "                            (0, 0, 0),\n",
    "                            thickness=3,\n",
    "                            lineType=cv2.LINE_AA,\n",
    "                        )\n",
    "                    for i in range(len(messages)):\n",
    "                        cv2.putText(\n",
    "                            image,\n",
    "                            messages[i],\n",
    "                            messages_coords[i],\n",
    "                            font,\n",
    "                            messages_fontscale[i],\n",
    "                            bbox_color,\n",
    "                            thickness=2,\n",
    "                            lineType=cv2.LINE_AA,\n",
    "                        )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fcos import build\n",
    "from data_processing.io import load_gmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = load_detection_ds(\"training/temp_dataset.yaml\")\n",
    "\n",
    "for sample in raw_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor([\n",
    "    image.LoadImage(),\n",
    "    bboxes.LoadBboxes(n_bboxes=90),\n",
    "    image.ResizeKeepRatio(300,400),\n",
    "    image.Normalize(),\n",
    "    bboxes.BuildFCOSTarget((300,400), [8])\n",
    "], feature_keys=None)\n",
    "\n",
    "processed_ds = raw_ds.map(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/fcos/snapshots/3e7a78331570bc3307935976e806ea78/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fcos.interpreter import Interpreter\n",
    "from data_processing.nms import nms\n",
    "from data_processing import io\n",
    "from data_processing.BboxDetectionReport import BboxDetectionReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = Interpreter('configs/interpreter.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf83c32e50d4523bcb51e2a4ff817b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "for sample in tqdm.tqdm_notebook(raw_ds.map(processor).batch(bs)):\n",
    "    raw_pred = model(sample['img'])\n",
    "    bboxes_pred = interpreter(raw_pred,  sample[\"src_img_bbox\"].numpy(), sample[\"original_shape\"].numpy())\n",
    "    bboxes_pred = nms(bboxes_pred, 0.2)\n",
    "    io.serialize(sample['img_path'].numpy(), bboxes_pred, 'data/images', 'data/logs/val_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_at_.8recall.5IoU': 0,\n",
       " 'precision_at_.9recall.5IoU': 0,\n",
       " 'recall_at_.8precision.5IoU': 0,\n",
       " 'recall_at_.9precision.5IoU': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = BboxDetectionReport()\n",
    "report.from_serialized_report('data/images_markup', 'data/logs/val_report', class_idx = 0)\n",
    "report.run_standard_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.pfr(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
